df_beltsalert = spark.read.format("parquet").load("abfss://azure-webjobs-.......")
df_beltsalert.show(8)

df_drivers = spark.read.format("csv").option("header", "true").option.("inferschema", "true").load("abfss://azure-webjobs-.......drivers.csv")
df_drivers.show(8)

driversbeltaler = (df_drivers.join(df_beltsalert, df_beltsalert.VehicleID == df_drivers.Unit))
driversbeltaler = driversbeltaler.select("Name", "Unit", "buckled")
display(driversbeltaler)

from pyspark.sql.functions import count, first

driversbeltaler = (df_drivers.join(df_beltsalert, df_beltsalert.VehicleID == df_drivers.Unit))
driversbeltaler = driversbeltaler.select("Name", "Unit", "buckled")

final_summary_df = driversbeltaler.groupBy("Name").agg(
  count("*").alias("total_belts_alert"),
  first("Unit").alias("Unit"),
  first("Buckled").alias("Buckled")
)
display(final_summary_df)

final_summary_df.write.mode("append").parquet.("abfss://azure--------")
